{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54a2d4ee-1e2f-4869-9f21-49e31448b5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ll/n97j7j6n4hl40jzcp14wv24m0000gn/T/ipykernel_15224/4051078519.py:6: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "/Users/lollipop/miniconda3/envs/pyro/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI\n",
    "import torch.distributions.constraints as constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dde4bd97-a377-401e-90c9-aaea63c9b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoke_test = ('CI' in os.environ)\n",
    "assert pyro.__version__.startswith('1.9.0')\n",
    "pyro.enable_validation(True)\n",
    "pyro.set_rng_seed(1)\n",
    "logging.basicConfig(format='%(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8f2b6d-2f6d-4e59-83e2-b6c666eb2372",
   "metadata": {},
   "source": [
    "We're modeling a joint distribution over observation matrix $D$, predicability matrix $R$, truth matrix $T$, and latent types $Z$.\n",
    "\n",
    "$D$ is an IxJ matrix where $I$ is the number of objects and $J$ is the number of predicates. $R$ is a $\\tau$xJ matrix, where $\\tau$ is the number of latent types. $T$ is a OxJ matrix. $Z$ is a 1x$\\tau$ matrix. All matrices are boolean, with exception to $Z$.\n",
    "\n",
    "$D_{i,j}$ refers to the observation of object $i$ being predicated by function $j$. $R_{i,j}$ refers to whether an object $i$ can be predicated by $j$, with $0$ meaning ``no`` and $1$ meaning ``yes``. $T_{i.j}$ refers to the expected truth-value of applying predicate $j$ to object $i$. $Z_i$ refers to the type of object $i$.\n",
    "\n",
    "$$\n",
    "    p(D, R, T, Z) \\propto p(D | R, T, Z)p(T | R, Z)p(R|Z)p(Z)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec8f9bcf-be39-4132-99d8-38708809ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_object_types(alpha=2,num_objs=10):\n",
    "  '''Function for generating cluster assignments from a CRP.\n",
    "\n",
    "  Arguments:\n",
    "    alpha: Concentration parameter.\n",
    "    n_objects: Number of objects to be clustered.\n",
    "\n",
    "  Returns:\n",
    "    cluster_assignments: Cluster assignments for each object.\n",
    "  '''\n",
    "  cluster_frequencies = [1]\n",
    "  cluster_assignments =[0]\n",
    "  n = num_objs-1\n",
    "  probs = torch.tensor([1/(1+alpha),alpha/(1+alpha)])\n",
    "  for i in range(n):\n",
    "    z_i = dist.Categorical(probs)().item()\n",
    "    total_customer = i + 1\n",
    "    if z_i in cluster_assignments:\n",
    "      cluster_frequencies[z_i] += 1\n",
    "    else:\n",
    "      cluster_frequencies += [ 1]\n",
    "    probs = [n/(total_customer + alpha) for n in cluster_frequencies+[alpha]]\n",
    "    probs = torch.tensor(probs)\n",
    "    cluster_assignments.append(z_i)\n",
    "  return torch.tensor(cluster_assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55301841-1243-492c-8e07-684fabcb4375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_pred_matrix(obj_types, num_preds, theta):\n",
    "  '''Function for generating predicability matrices.\n",
    "\n",
    "  Arguments:\n",
    "    obj_types: Tensor of object type assignments.\n",
    "    num_preds: Number of predicates.\n",
    "    theta: Sucess parameter for Bernoulli.\n",
    "\n",
    "  Returns:\n",
    "    pred_matrix: Predicability matrix.\n",
    "  '''\n",
    "  num_types = len(torch.unique(obj_types))\n",
    "  pred_matrix = torch.bernoulli(torch.ones(num_types, num_preds)*theta)\n",
    "  return pred_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a82cf79e-ee4e-4280-9739-e862db9d1e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_truth_matrix(pred_matrix, obj_types, pi):\n",
    "  '''Function for generating truth-value matrices.\n",
    "\n",
    "  Arguments:\n",
    "    pred_matrix: Predicability matrix.\n",
    "    obj_types: List of object type assignments.\n",
    "    pi: Success parameter for Bernoulli.\n",
    "\n",
    "  Returns:\n",
    "    truth_matrix: Predicability matrix.\n",
    "  '''\n",
    "  num_objs = len(obj_types)\n",
    "  num_preds = pred_matrix.size()[1]\n",
    "  truth_matrix = torch.zeros(num_objs, num_preds)\n",
    "  for i in range(num_objs):\n",
    "    for j in range(num_preds):\n",
    "      if pred_matrix[z[i],j]==1:\n",
    "        truth_matrix[i,j] = pyro.sample(\"t\", dist.Bernoulli(pi)).item()\n",
    "      else:\n",
    "        truth_matrix[i,j] = 0\n",
    "  return truth_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "42886e85-9866-4a97-8f3b-c49e9d34c994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_freq_matrix(truth_matrix, pred_matrix, obj_types):\n",
    "  '''Function for generating frequency matrices.\n",
    "\n",
    "  Arguments:\n",
    "    pred_matrix: Predicability matrix.\n",
    "    obj_types: List of object type assignments.\n",
    "    truth_matrix: Truth matrix.\n",
    "\n",
    "  Returns:\n",
    "    freq_matrix: Frequency matrix.\n",
    "  '''\n",
    "  num_objs = len(obj_types)\n",
    "  num_preds = pred_matrix.size()[1]\n",
    "  freq_matrix = torch.zeros(num_objs, num_preds)\n",
    "  for i in range(num_objs):\n",
    "    for j in range(num_preds):\n",
    "      if pred_matrix[z[i],j]==1:\n",
    "        freq_matrix[i,j] = truth_matrix[i,j]\n",
    "      else:\n",
    "        freq_matrix[i,j] = -1\n",
    "  return freq_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdebad1-c216-4492-b61a-2b3e68697e02",
   "metadata": {},
   "source": [
    "# Synthetic data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e040b06-6cf1-468a-a105-ef3c5afe67da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta 0.600306510925293 Pi 0.4010412395000458\n"
     ]
    }
   ],
   "source": [
    "# Number of objects\n",
    "num_objs = 5\n",
    "# Number of predicates\n",
    "num_preds = 5\n",
    "# Concentration param\n",
    "alpha = 10\n",
    "# Success parameter for predicability\n",
    "theta = pyro.sample(\"theta\", dist.Beta(1,1)).item()\n",
    "# Success parameter for truth\n",
    "pi = pyro.sample(\"pi\", dist.Beta(1,1)).item()\n",
    "print(f\"Theta {theta} Pi {pi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4917153-d535-42f6-bb76-ac90ec9387c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object type assignments:\n",
      "tensor([0, 1, 2, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "# Object type assignments\n",
    "z = create_data_object_types(alpha=alpha, num_objs=num_objs)\n",
    "print(\"Object type assignments:\")\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07d432dd-3df5-454d-a117-705212b4457f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicability matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 0., 1.],\n",
       "        [0., 1., 1., 1., 1.],\n",
       "        [0., 1., 0., 0., 1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = create_data_pred_matrix(obj_types=z, num_preds=num_preds, theta=theta)\n",
    "print(\"Predicability matrix:\")\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d2f2978-7aab-4849-b680-538f9f111b9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 1.],\n",
       "        [0., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = create_data_truth_matrix(pred_matrix=r, obj_types=z, pi=pi)\n",
    "print(\"Truth matrix:\")\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ca2bf1e-9c11-4a9e-8c1c-17244ad846aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freq matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.,  1.,  0., -1.,  0.],\n",
       "        [-1.,  1.,  0.,  0.,  0.],\n",
       "        [-1.,  1., -1., -1.,  0.],\n",
       "        [-1.,  0.,  0.,  1.,  1.],\n",
       "        [-1.,  0.,  1., -1.,  0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = create_data_freq_matrix(truth_matrix=t, pred_matrix=r, obj_types=z)\n",
    "print(\"Freq matrix:\")\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a34c43-8da8-4b4f-998e-6a8bb167acdb",
   "metadata": {},
   "source": [
    "# Model and inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87253d0c-9cd8-4496-9167-1717568a93a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(freq_matrix):\n",
    "  '''A Pyro model for the TIRM model.\n",
    "\n",
    "  Arguments:\n",
    "    freq_matrix: The frequency matrix of observations.\n",
    "\n",
    "  Notes:\n",
    "    Currently not sampling alpha.\n",
    "  '''\n",
    "  # Model parameters\n",
    "  theta = pyro.param(\"theta\", torch.tensor(0.5), constraint=constraints.interval(0., 1.0))\n",
    "  pi = pyro.param(\"pi\", torch.tensor(0.5), constraint=constraints.interval(0., 1.0))\n",
    "  alpha = pyro.param(\"alpha\", torch.tensor(10), constraint=constraints.positive)\n",
    "  # Useful variables\n",
    "  num_objs = freq_matrix.size()[0]\n",
    "  num_preds = freq_matrix.size()[1]\n",
    "  obj_axis = pyro.plate(\"obj_axis\", num_objs)\n",
    "  pred_axis = pyro.plate(\"pred_axis\", num_preds)\n",
    "  # p(Z), modeled by a CRP\n",
    "  freqs = [] # number of customers at each table\n",
    "  for i in range(num_objs):\n",
    "    probs = torch.tensor(freqs + [alpha])\n",
    "    probs /= probs.sum()\n",
    "    z_sample = pyro.sample(f\"z_{i}\", dist.Categorical(probs))\n",
    "    z_item = z_sample.item()\n",
    "    if z_item >= len(freqs):\n",
    "      freqs += [1.]\n",
    "    else:\n",
    "      freqs[z_item] += 1.\n",
    "  # We sample z ~ p(alpha)\n",
    "  with obj_axis:\n",
    "    z = pyro.sample(\"z\", dist.Categorical(probs))\n",
    "  type_axis = pyro.plate(\"type_axis\", max(z)+1)\n",
    "  # p(R | Z)\n",
    "  with obj_axis, type_axis:\n",
    "    r = pyro.sample(\"r\", dist.Bernoulli(theta))\n",
    "  # Pad R since it changes depending on z\n",
    "  r = F.pad(input=r, pad=(0,0,0,num_objs-r.shape[0]), mode='constant', value=0)\n",
    "  with obj_axis, pred_axis:\n",
    "    # p (T | R, Z)\n",
    "    t = pyro.sample(\"t\", dist.Bernoulli(r[z]*pi))\n",
    "    # p (D | T, R, Z)\n",
    "    obs = t+(r[z]-1)\n",
    "    d = pyro.sample(\"d\", dist.Delta(obs), obs=freq_matrix)\n",
    "  return z, r, t, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d1f28dd-ae33-46aa-9a5c-10a2de6ee8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guide(freq_matrix):\n",
    "  # Model parameters\n",
    "  theta = pyro.param(\"theta\", torch.tensor(.7), constraint=constraints.interval(0., 1.0))\n",
    "  # pi = pyro.param(\"pi\", torch.tensor(.7), constraint=constraints.interval(0., 1.0))\n",
    "  alpha = pyro.param(\"alpha\", torch.tensor(10), constraint=constraints.positive)\n",
    "  # Useful variables\n",
    "  num_objs = freq_matrix.size()[0]\n",
    "  num_preds = freq_matrix.size()[1]\n",
    "  freqs = [] # number of customers at each table\n",
    "  for i in range(num_objs):\n",
    "    probs = torch.tensor(freqs + [alpha])\n",
    "    probs /= probs.sum()\n",
    "    z_sample = pyro.sample(f\"z_{i}\", dist.Categorical(probs))\n",
    "    z_item = z_sample.item()\n",
    "    if z_item >= len(freqs):\n",
    "      freqs += [1.]\n",
    "    else:\n",
    "      freqs[z_item] += 1.\n",
    "  obj_axis = pyro.plate(\"obj_axis\", num_objs)\n",
    "  # pred_axis = pyro.plate(\"pred_axis\", num_preds)\n",
    "  with obj_axis:\n",
    "    z = pyro.sample(\"z\", dist.Categorical(probs))\n",
    "  type_axis = pyro.plate(\"type_axis\", max(z)+1)\n",
    "  with obj_axis, type_axis:\n",
    "    r = pyro.sample(\"r\", dist.Bernoulli(theta))\n",
    "  r = F.pad(input=r, pad=(0,0,0,num_objs-r.shape[0]), mode='constant', value=0)\n",
    "  with obj_axis, pred_axis:\n",
    "    t = pyro.sample(\"t\", dist.Bernoulli(r[z]*pi))\n",
    "    # obs = t+(r[z]-1)\n",
    "    # d = pyro.sample(\"d\", dist.Delta(obs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196f11a3-a9a8-4551-8246-a3a17b3c3f31",
   "metadata": {},
   "source": [
    "## Variational inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "id": "93633dcc-9a43-4127-93f8-cc92814b5b87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 tensor(2)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error while computing log_prob at site 'r':\nValue is not broadcastable with batch_shape+event_shape: torch.Size([2, 5]) vs torch.Size([2, 2]).\nTrace Shapes:      \n Param Sites:      \n        theta      \n        alpha      \nSample Sites:      \n     z_0 dist     |\n        value     |\n     log_prob     |\n     z_1 dist     |\n        value     |\n     log_prob     |\n       z dist   2 |\n        value   2 |\n     log_prob   2 |\n       r dist 2 2 |\n        value 2 5 |",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/pyro/lib/python3.12/site-packages/pyro/poutine/trace_struct.py:264\u001b[0m, in \u001b[0;36mTrace.compute_log_prob\u001b[0;34m(self, site_filter)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 264\u001b[0m     log_p \u001b[38;5;241m=\u001b[39m \u001b[43msite\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43msite\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msite\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msite\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkwargs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/pyro/lib/python3.12/site-packages/torch/distributions/bernoulli.py:109\u001b[0m, in \u001b[0;36mBernoulli.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_args:\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m logits, value \u001b[38;5;241m=\u001b[39m broadcast_all(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogits, value)\n",
      "File \u001b[0;32m~/miniconda3/envs/pyro/lib/python3.12/site-packages/torch/distributions/distribution.py:297\u001b[0m, in \u001b[0;36mDistribution._validate_sample\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m j \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m j:\n\u001b[0;32m--> 297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    298\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue is not broadcastable with batch_shape+event_shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactual_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m         )\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Value is not broadcastable with batch_shape+event_shape: torch.Size([2, 5]) vs torch.Size([2, 2]).",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1007], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m num_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_steps):\n\u001b[0;32m----> 5\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43msvi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: loss = \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(step, loss))\n",
      "File \u001b[0;32m~/miniconda3/envs/pyro/lib/python3.12/site-packages/pyro/infer/svi.py:145\u001b[0m, in \u001b[0;36mSVI.step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# get loss and compute gradients\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m poutine\u001b[38;5;241m.\u001b[39mtrace(param_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m param_capture:\n\u001b[0;32m--> 145\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_and_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\n\u001b[1;32m    148\u001b[0m     site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munconstrained() \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m param_capture\u001b[38;5;241m.\u001b[39mtrace\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# actually perform gradient steps\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# torch.optim objects gets instantiated for any params that haven't been seen yet\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyro/lib/python3.12/site-packages/pyro/infer/traceenum_elbo.py:451\u001b[0m, in \u001b[0;36mTraceEnum_ELBO.loss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m:returns: an estimate of the ELBO\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;124;03m:rtype: float\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03mPerforms backward on the ELBO of each particle.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    450\u001b[0m elbo \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m--> 451\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide_trace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_traces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43melbo_particle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_compute_dice_elbo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide_trace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_identically_zero\u001b[49m\u001b[43m(\u001b[49m\u001b[43melbo_particle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyro/lib/python3.12/site-packages/pyro/infer/traceenum_elbo.py:374\u001b[0m, in \u001b[0;36mTraceEnum_ELBO._get_traces\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraceEnum_ELBO does not support GuideMessenger\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_plate_nesting \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 374\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_guess_max_plate_nesting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorize_particles:\n\u001b[1;32m    376\u001b[0m     guide \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vectorized_num_particles(guide)\n",
      "File \u001b[0;32m~/miniconda3/envs/pyro/lib/python3.12/site-packages/pyro/infer/elbo.py:171\u001b[0m, in \u001b[0;36mELBO._guess_max_plate_nesting\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_validation_enabled():\n\u001b[1;32m    170\u001b[0m     guide_trace\u001b[38;5;241m.\u001b[39mcompute_log_prob()\n\u001b[0;32m--> 171\u001b[0m     \u001b[43mmodel_trace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m sites:\n\u001b[1;32m    173\u001b[0m         check_site_shape(site, max_plate_nesting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/pyro/lib/python3.12/site-packages/pyro/poutine/trace_struct.py:270\u001b[0m, in \u001b[0;36mTrace.compute_log_prob\u001b[0;34m(self, site_filter)\u001b[0m\n\u001b[1;32m    268\u001b[0m     _, exc_value, traceback \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n\u001b[1;32m    269\u001b[0m     shapes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_shapes(last_site\u001b[38;5;241m=\u001b[39msite[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while computing log_prob at site \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    272\u001b[0m             name, exc_value, shapes\n\u001b[1;32m    273\u001b[0m         )\n\u001b[1;32m    274\u001b[0m     )\u001b[38;5;241m.\u001b[39mwith_traceback(traceback) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    275\u001b[0m site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munscaled_log_prob\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m log_p\n\u001b[1;32m    276\u001b[0m log_p \u001b[38;5;241m=\u001b[39m scale_and_mask(log_p, site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m\"\u001b[39m], site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/pyro/lib/python3.12/site-packages/pyro/poutine/trace_struct.py:264\u001b[0m, in \u001b[0;36mTrace.compute_log_prob\u001b[0;34m(self, site_filter)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_prob\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m site:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 264\u001b[0m         log_p \u001b[38;5;241m=\u001b[39m \u001b[43msite\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m            \u001b[49m\u001b[43msite\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msite\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msite\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkwargs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    268\u001b[0m         _, exc_value, traceback \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/miniconda3/envs/pyro/lib/python3.12/site-packages/torch/distributions/bernoulli.py:109\u001b[0m, in \u001b[0;36mBernoulli.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_args:\n\u001b[0;32m--> 109\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     logits, value \u001b[38;5;241m=\u001b[39m broadcast_all(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogits, value)\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mbinary_cross_entropy_with_logits(logits, value, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pyro/lib/python3.12/site-packages/torch/distributions/distribution.py:297\u001b[0m, in \u001b[0;36mDistribution._validate_sample\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(actual_shape), \u001b[38;5;28mreversed\u001b[39m(expected_shape)):\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m j \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m j:\n\u001b[0;32m--> 297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    298\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue is not broadcastable with batch_shape+event_shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactual_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m         )\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m     support \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport\n",
      "\u001b[0;31mValueError\u001b[0m: Error while computing log_prob at site 'r':\nValue is not broadcastable with batch_shape+event_shape: torch.Size([2, 5]) vs torch.Size([2, 2]).\nTrace Shapes:      \n Param Sites:      \n        theta      \n        alpha      \nSample Sites:      \n     z_0 dist     |\n        value     |\n     log_prob     |\n     z_1 dist     |\n        value     |\n     log_prob     |\n       z dist   2 |\n        value   2 |\n     log_prob   2 |\n       r dist 2 2 |\n        value 2 5 |"
     ]
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "svi = SVI(model, guide, pyro.optim.Adam({\"lr\": 1}), loss=pyro.infer.TraceEnum_ELBO())\n",
    "num_steps = 1000\n",
    "for step in range(num_steps):\n",
    "    loss = svi.step(r)\n",
    "    if step % 100 == 0:\n",
    "        print(\"Step {}: loss = {:.2f}\".format(step, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "id": "2efacb10-6a8a-4f93-9379-e0ddf4fe1006",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = {param: pyro.param(param).detach().clone() for param in pyro.get_param_store().keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "id": "04d26df4-d658-46a7-aa1f-427454c68771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'theta': tensor(1.0000), 'pi': tensor(0.0800), 'alpha': tensor(10.)}"
      ]
     },
     "execution_count": 977,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40329c80-a739-48d6-904e-df0465e828e1",
   "metadata": {},
   "source": [
    "## MCMC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "id": "962eacf6-34ce-43df-a391-abb57ab50a51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample [0]: 100%|█████████████████████████████████| 1100/1100 [00:00, 30432.20it/s, step size=1.00e+00, acc. prob=1.000]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "tensor([0.0833, 0.0833, 0.8333])\n",
      "tensor([0.0769, 0.0769, 0.0769, 0.7692])\n",
      "tensor([0.0714, 0.0714, 0.0714, 0.0714, 0.7143])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample [1]: 100%|█████████████████████████████████| 1100/1100 [00:00, 37270.66it/s, step size=1.00e+00, acc. prob=1.000]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "tensor([0.0833, 0.0833, 0.8333])\n",
      "tensor([0.0769, 0.0769, 0.0769, 0.7692])\n",
      "tensor([0.0714, 0.0714, 0.0714, 0.0714, 0.7143])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample [2]: 100%|█████████████████████████████████| 1100/1100 [00:00, 36940.31it/s, step size=1.00e+00, acc. prob=1.000]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "tensor([0.0833, 0.0833, 0.8333])\n",
      "tensor([0.1538, 0.0769, 0.7692])\n",
      "tensor([0.1429, 0.1429, 0.7143])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample [3]: 100%|█████████████████████████████████| 1100/1100 [00:00, 37601.75it/s, step size=1.00e+00, acc. prob=1.000]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "tensor([0.0833, 0.0833, 0.8333])\n",
      "tensor([0.0769, 0.0769, 0.0769, 0.7692])\n",
      "tensor([0.0714, 0.0714, 0.0714, 0.0714, 0.7143])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample [4]: 100%|█████████████████████████████████| 1100/1100 [00:00, 37284.21it/s, step size=1.00e+00, acc. prob=1.000]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "tensor([0.0833, 0.0833, 0.8333])\n",
      "tensor([0.0769, 0.0769, 0.0769, 0.7692])\n",
      "tensor([0.0714, 0.0714, 0.0714, 0.0714, 0.7143])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample [5]: 100%|█████████████████████████████████| 1100/1100 [00:00, 36703.16it/s, step size=1.00e+00, acc. prob=1.000]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "tensor([0.0833, 0.0833, 0.8333])\n",
      "tensor([0.0769, 0.1538, 0.7692])\n",
      "tensor([0.1429, 0.1429, 0.7143])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   0%|                                                                                                                                                                               | 0/1100 [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "tensor([0.0833, 0.0833, 0.8333])\n",
      "tensor([0.0769, 0.0769, 0.0769, 0.7692])\n",
      "tensor([0.0714, 0.0714, 0.0714, 0.0714, 0.7143])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample [6]: 100%|█████████████████████████████████| 1100/1100 [00:00, 33428.50it/s, step size=1.00e+00, acc. prob=1.000]                                                                                           \n",
      "Warmup:   0%|                                                                                                                                                                               | 0/1100 [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "tensor([0.0833, 0.0833, 0.8333])\n",
      "tensor([0.0769, 0.0769, 0.0769, 0.7692])\n",
      "tensor([0.1429, 0.0714, 0.0714, 0.7143])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample [7]: 100%|█████████████████████████████████| 1100/1100 [00:00, 36868.29it/s, step size=1.00e+00, acc. prob=1.000]                                                                                           \n",
      "Warmup:   0%|                                                                                                                                                                               | 0/1100 [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "tensor([0.0833, 0.0833, 0.8333])\n",
      "tensor([0.0769, 0.0769, 0.0769, 0.7692])\n",
      "tensor([0.0714, 0.0714, 0.0714, 0.0714, 0.7143])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample [8]: 100%|█████████████████████████████████| 1100/1100 [00:00, 35496.54it/s, step size=1.00e+00, acc. prob=1.000]                                                                                           \n",
      "Warmup:   0%|                                                                                                                                                                               | 0/1100 [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "tensor([0.1667, 0.8333])\n",
      "tensor([0.1538, 0.0769, 0.7692])\n",
      "tensor([0.1429, 0.1429, 0.7143])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample [9]: 100%|█████████████████████████████████| 1100/1100 [00:00, 37103.41it/s, step size=1.00e+00, acc. prob=1.000]                                                                                           \n"
     ]
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "nuts_kernel = NUTS(model=model)\n",
    "mcmc = MCMC(kernel=nuts_kernel, num_samples=1000, num_chains=10, warmup_steps=100)\n",
    "posterior = mcmc.run(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be790d0-3f2b-4599-a8f5-8a095af243a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
