{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "54a2d4ee-1e2f-4869-9f21-49e31448b5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.infer import SVI\n",
    "import torch.distributions.constraints as constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dde4bd97-a377-401e-90c9-aaea63c9b2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "smoke_test = ('CI' in os.environ)\n",
    "assert pyro.__version__.startswith('1.9.0')\n",
    "\n",
    "pyro.enable_validation(True)\n",
    "pyro.set_rng_seed(1)\n",
    "logging.basicConfig(format='%(message)s', level=logging.INFO)\n",
    "\n",
    "# Set matplotlib settings\n",
    "%matplotlib inline\n",
    "plt.style.use('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec8f9bcf-be39-4132-99d8-38708809ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_object_types(alpha=2,num_objs=10):\n",
    "  '''Function for generating cluster assignments from a CRP.\n",
    "\n",
    "  Arguments:\n",
    "    alpha: Concentration parameter.\n",
    "    n_objects: Number of objects to be clustered.\n",
    "\n",
    "  Returns:\n",
    "    cluster_assignments: Cluster assignments for each object.\n",
    "  '''\n",
    "  cluster_frequencies = [1]\n",
    "  cluster_assignments =[0]\n",
    "  n = num_objs-1\n",
    "  probs = torch.tensor([1/(1+alpha),alpha/(1+alpha)])\n",
    "  for i in range(n):\n",
    "    z_i = dist.Categorical(probs)().item()\n",
    "    total_customer = i + 1\n",
    "    if z_i in cluster_assignments:\n",
    "      cluster_frequencies[z_i] += 1\n",
    "    else:\n",
    "      cluster_frequencies += [ 1]\n",
    "    probs = [n/(total_customer + alpha) for n in cluster_frequencies+[alpha]]\n",
    "    probs = torch.tensor(probs)\n",
    "    cluster_assignments.append(z_i)\n",
    "  return torch.tensor(cluster_assignments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55301841-1243-492c-8e07-684fabcb4375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_pred_matrix(obj_types, num_preds, theta):\n",
    "  '''Function for generating predicability matrices.\n",
    "\n",
    "  Arguments:\n",
    "    obj_types: Tensor of object type assignments.\n",
    "    num_preds: Number of predicates.\n",
    "    theta: Sucess parameter for Bernoulli.\n",
    "\n",
    "  Returns:\n",
    "    pred_matrix: Predicability matrix.\n",
    "  '''\n",
    "  num_types = len(torch.unique(obj_types))\n",
    "  pred_matrix = torch.bernoulli(torch.ones(num_types, num_preds)*theta)\n",
    "  return pred_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a82cf79e-ee4e-4280-9739-e862db9d1e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_truth_matrix(pred_matrix, obj_types, pi):\n",
    "  '''Function for generating truth-value matrices.\n",
    "\n",
    "  Arguments:\n",
    "    pred_matrix: Predicability matrix.\n",
    "    obj_types: List of object type assignments.\n",
    "    pi: Success parameter for Bernoulli.\n",
    "\n",
    "  Returns:\n",
    "    truth_matrix: Predicability matrix.\n",
    "  '''\n",
    "  num_objs = len(obj_types)\n",
    "  num_preds = pred_matrix.size()[1]\n",
    "  truth_matrix = torch.zeros(num_objs, num_preds)\n",
    "  for i in range(num_objs):\n",
    "    for j in range(num_preds):\n",
    "      if pred_matrix[z[i],j]==1:\n",
    "        truth_matrix[i,j] = pyro.sample(\"t\", dist.Bernoulli(pi)).item()\n",
    "      else:\n",
    "        truth_matrix[i,j] = 0\n",
    "  return truth_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42886e85-9866-4a97-8f3b-c49e9d34c994",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_freq_matrix(truth_matrix, pred_matrix, obj_types):\n",
    "  '''Function for generating frequency matrices.\n",
    "\n",
    "  Arguments:\n",
    "    pred_matrix: Predicability matrix.\n",
    "    obj_types: List of object type assignments.\n",
    "    truth_matrix: Truth matrix.\n",
    "\n",
    "  Returns:\n",
    "    freq_matrix: Frequency matrix.\n",
    "  '''\n",
    "  num_objs = len(obj_types)\n",
    "  num_preds = pred_matrix.size()[1]\n",
    "  freq_matrix = torch.zeros(num_objs, num_preds)\n",
    "  for i in range(num_objs):\n",
    "    for j in range(num_preds):\n",
    "      if pred_matrix[z[i],j]==1:\n",
    "        freq_matrix[i,j] = truth_matrix[i,j]\n",
    "      else:\n",
    "        freq_matrix[i,j] = -1\n",
    "  return freq_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "4e040b06-6cf1-468a-a105-ef3c5afe67da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta 0.5328394770622253 Pi 0.255874365568161\n"
     ]
    }
   ],
   "source": [
    "# Number of objects\n",
    "num_objs = 5\n",
    "# Number of predicates\n",
    "num_preds = 5\n",
    "# Concentration param\n",
    "alpha = 10\n",
    "# Success parameter for predicability\n",
    "theta = pyro.sample(\"theta\", dist.Beta(1,1)).item()\n",
    "# Success parameter for truth\n",
    "pi = pyro.sample(\"pi\", dist.Beta(1,1)).item()\n",
    "print(f\"Theta {theta} Pi {pi}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "c4917153-d535-42f6-bb76-ac90ec9387c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object type assignments:\n",
      "tensor([0, 1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# Object type assignments\n",
    "z = create_data_object_types(alpha=alpha, num_objs=num_objs)\n",
    "print(\"Object type assignments:\")\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "id": "07d432dd-3df5-454d-a117-705212b4457f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicability matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 1.],\n",
       "        [0., 0., 1., 1., 0.]])"
      ]
     },
     "execution_count": 990,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = create_data_pred_matrix(obj_types=z, num_preds=num_preds, theta=theta)\n",
    "print(\"Predicability matrix:\")\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "8d2f2978-7aab-4849-b680-538f9f111b9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 1.],\n",
       "        [1., 0., 1., 1., 0.],\n",
       "        [0., 1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = create_data_truth_matrix(pred_matrix=r, obj_types=z, pi=pi)\n",
    "print(\"Truth matrix:\")\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "4ca2bf1e-9c11-4a9e-8c1c-17244ad846aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freq matrix:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-1.,  0., -1., -1.,  1.],\n",
       "        [ 1.,  0.,  1.,  1., -1.],\n",
       "        [ 0.,  1., -1., -1.,  0.],\n",
       "        [ 1., -1.,  0.,  0., -1.],\n",
       "        [ 0., -1., -1., -1.,  0.]])"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = create_data_freq_matrix(truth_matrix=t, pred_matrix=r, obj_types=z)\n",
    "print(\"Freq matrix:\")\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "id": "87253d0c-9cd8-4496-9167-1717568a93a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(freq_matrix):\n",
    "  '''A Pyro model for the TIRM model.\n",
    "\n",
    "  Arguments:\n",
    "    freq_matrix: The frequency matrix of observations.\n",
    "\n",
    "  Notes:\n",
    "    Currently not sampling alpha.\n",
    "  '''\n",
    "  # Model parameters\n",
    "  theta = pyro.param(\"theta\", torch.tensor(0.5), constraint=constraints.interval(0., 1.0))\n",
    "  # pi = pyro.param(\"pi\", torch.tensor(0.5), constraint=constraints.interval(0., 1.0))\n",
    "  alpha = pyro.param(\"alpha\", torch.tensor(10), constraint=constraints.positive)\n",
    "  # Useful variables\n",
    "  num_objs = freq_matrix.size()[0]\n",
    "  num_preds = freq_matrix.size()[1]\n",
    "  freqs = [] # number of customers at each table\n",
    "  for i in range(num_objs):\n",
    "    probs = torch.tensor(freqs + [alpha])\n",
    "    probs /= probs.sum()\n",
    "    z_sample = pyro.sample(f\"z_{i}\", dist.Categorical(probs))\n",
    "    z_item = z_sample.item()\n",
    "    if z_item >= len(freqs):\n",
    "      freqs += [1.]\n",
    "    else:\n",
    "      freqs[z_item] += 1.\n",
    "  obj_axis = pyro.plate(\"obj_axis\", num_objs)\n",
    "  pred_axis = pyro.plate(\"pred_axis\", num_preds)\n",
    "  with obj_axis:\n",
    "    z = pyro.sample(\"z\", dist.Categorical(probs))\n",
    "  type_axis = pyro.plate(\"type_axis\", max(z)+1)\n",
    "  with obj_axis, type_axis:\n",
    "    r = pyro.sample(\"r\", dist.Bernoulli(theta), obs=freq_matrix)\n",
    "  # r = F.pad(input=r, pad=(0,0,0,num_objs-r.shape[0]), mode='constant', value=0)\n",
    "  # with obj_axis, pred_axis:\n",
    "  #   t = pyro.sample(\"t\", dist.Bernoulli(r[z]*pi), obs=freq_matrix)\n",
    "    # obs = t+(r[z]-1)\n",
    "    # d = pyro.sample(\"d\", dist.Delta(obs), obs=freq_matrix)\n",
    "  # return z, r, t, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5359c21-41b3-4d4b-bd79-3611c882ed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(freq_matrix):\n",
    "  '''A Pyro model for the TIRM model.\n",
    "\n",
    "  Arguments:\n",
    "    freq_matrix: The frequency matrix of observations.\n",
    "\n",
    "  Notes:\n",
    "    Currently not sampling alpha.\n",
    "  '''\n",
    "  # Model parameters\n",
    "  theta = pyro.param(\"theta\", torch.tensor(0.5), constraint=constraints.interval(0., 1.0))\n",
    "  # pi = pyro.param(\"pi\", torch.tensor(0.5), constraint=constraints.interval(0., 1.0))\n",
    "  alpha = pyro.param(\"alpha\", torch.tensor(10), constraint=constraints.positive)\n",
    "  # Useful variables\n",
    "  num_objs = freq_matrix.size()[0]\n",
    "  num_preds = freq_matrix.size()[1]\n",
    "  freqs = [] # number of customers at each table\n",
    "  for i in range(num_objs):\n",
    "    probs = torch.tensor(freqs + [alpha])\n",
    "    probs /= probs.sum()\n",
    "    z_sample = pyro.sample(f\"z_{i}\", dist.Categorical(probs))\n",
    "    z_item = z_sample.item()\n",
    "    if z_item >= len(freqs):\n",
    "      freqs += [1.]\n",
    "    else:\n",
    "      freqs[z_item] += 1.\n",
    "  obj_axis = pyro.plate(\"obj_axis\", num_objs)\n",
    "  pred_axis = pyro.plate(\"pred_axis\", num_preds)\n",
    "  with obj_axis:\n",
    "    z = pyro.sample(\"z\", dist.Categorical(probs))\n",
    "  type_axis = pyro.plate(\"type_axis\", max(z)+1)\n",
    "  with obj_axis, type_axis:\n",
    "    r = pyro.sample(f\"r_{i}\", dist.Bernoulli(theta), obs=freq_matrix)\n",
    "  # r = F.pad(input=r, pad=(0,0,0,num_objs-r.shape[0]), mode='constant', value=0)\n",
    "  # with obj_axis, pred_axis:\n",
    "  #   t = pyro.sample(\"t\", dist.Bernoulli(r[z]*pi), obs=freq_matrix)\n",
    "    # obs = t+(r[z]-1)\n",
    "    # d = pyro.sample(\"d\", dist.Delta(obs), obs=freq_matrix)\n",
    "  # return z, r, t, d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "id": "7d1f28dd-ae33-46aa-9a5c-10a2de6ee8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guide(freq_matrix):\n",
    "  # Model parameters\n",
    "  theta = pyro.param(\"theta\", torch.tensor(.7), constraint=constraints.interval(0., 1.0))\n",
    "  # pi = pyro.param(\"pi\", torch.tensor(.7), constraint=constraints.interval(0., 1.0))\n",
    "  alpha = pyro.param(\"alpha\", torch.tensor(10), constraint=constraints.positive)\n",
    "  # Useful variables\n",
    "  num_objs = freq_matrix.size()[0]\n",
    "  num_preds = freq_matrix.size()[1]\n",
    "  freqs = [] # number of customers at each table\n",
    "  for i in range(num_objs):\n",
    "    probs = torch.tensor(freqs + [alpha])\n",
    "    probs /= probs.sum()\n",
    "    z_sample = pyro.sample(f\"z_{i}\", dist.Categorical(probs))\n",
    "    z_item = z_sample.item()\n",
    "    if z_item >= len(freqs):\n",
    "      freqs += [1.]\n",
    "    else:\n",
    "      freqs[z_item] += 1.\n",
    "  obj_axis = pyro.plate(\"obj_axis\", num_objs)\n",
    "  # pred_axis = pyro.plate(\"pred_axis\", num_preds)\n",
    "  with obj_axis:\n",
    "    z = pyro.sample(\"z\", dist.Categorical(probs))\n",
    "  # type_axis = pyro.plate(\"type_axis\", max(z)+1)\n",
    "  # with obj_axis, type_axis:\n",
    "  #   r = pyro.sample(\"r\", dist.Bernoulli(theta))\n",
    "  # r = F.pad(input=r, pad=(0,0,0,num_objs-r.shape[0]), mode='constant', value=0)\n",
    "  # with obj_axis, pred_axis:\n",
    "  #   t = pyro.sample(\"t\", dist.Bernoulli(r[z]*pi))\n",
    "    # obs = t+(r[z]-1)\n",
    "    # d = pyro.sample(\"d\", dist.Delta(obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 995,
   "id": "6327f2c5-b752-41cc-a700-39af4db770c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 2, 4, 4])"
      ]
     },
     "execution_count": 995,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "id": "93633dcc-9a43-4127-93f8-cc92814b5b87",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error while computing log_prob at site 'r':\nValue is not broadcastable with batch_shape+event_shape: torch.Size([2, 5]) vs torch.Size([1, 2]).\nTrace Shapes:      \n Param Sites:      \n        theta      \n        alpha      \nSample Sites:      \n     z_0 dist     |\n        value     |\n     log_prob     |\n     z_1 dist     |\n        value     |\n     log_prob     |\n       z dist   2 |\n        value   2 |\n     log_prob   2 |\n       r dist 1 2 |\n        value 2 5 |",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/pyro/lib/python3.12/site-packages/pyro/poutine/trace_struct.py:264\u001b[0m, in \u001b[0;36mTrace.compute_log_prob\u001b[0;34m(self, site_filter)\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 264\u001b[0m     log_p \u001b[38;5;241m=\u001b[39m \u001b[43msite\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m        \u001b[49m\u001b[43msite\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msite\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msite\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkwargs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/miniconda3/envs/pyro/lib/python3.12/site-packages/torch/distributions/bernoulli.py:109\u001b[0m, in \u001b[0;36mBernoulli.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_args:\n\u001b[0;32m--> 109\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m logits, value \u001b[38;5;241m=\u001b[39m broadcast_all(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogits, value)\n",
      "File \u001b[0;32m~/miniconda3/envs/pyro/lib/python3.12/site-packages/torch/distributions/distribution.py:297\u001b[0m, in \u001b[0;36mDistribution._validate_sample\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m j \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m j:\n\u001b[0;32m--> 297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    298\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue is not broadcastable with batch_shape+event_shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactual_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m         )\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mValueError\u001b[0m: Value is not broadcastable with batch_shape+event_shape: torch.Size([2, 5]) vs torch.Size([1, 2]).",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[994], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m num_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_steps):\n\u001b[0;32m----> 5\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43msvi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStep \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: loss = \u001b[39m\u001b[38;5;132;01m{:.2f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(step, loss))\n",
      "File \u001b[0;32m~/miniconda3/envs/pyro/lib/python3.12/site-packages/pyro/infer/svi.py:145\u001b[0m, in \u001b[0;36mSVI.step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# get loss and compute gradients\u001b[39;00m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m poutine\u001b[38;5;241m.\u001b[39mtrace(param_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m param_capture:\n\u001b[0;32m--> 145\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_and_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\n\u001b[1;32m    148\u001b[0m     site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39munconstrained() \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m param_capture\u001b[38;5;241m.\u001b[39mtrace\u001b[38;5;241m.\u001b[39mnodes\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    149\u001b[0m )\n\u001b[1;32m    151\u001b[0m \u001b[38;5;66;03m# actually perform gradient steps\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;66;03m# torch.optim objects gets instantiated for any params that haven't been seen yet\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyro/lib/python3.12/site-packages/pyro/infer/traceenum_elbo.py:451\u001b[0m, in \u001b[0;36mTraceEnum_ELBO.loss_and_grads\u001b[0;34m(self, model, guide, *args, **kwargs)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m:returns: an estimate of the ELBO\u001b[39;00m\n\u001b[1;32m    445\u001b[0m \u001b[38;5;124;03m:rtype: float\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03mPerforms backward on the ELBO of each particle.\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    450\u001b[0m elbo \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m--> 451\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide_trace\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_traces\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m    \u001b[49m\u001b[43melbo_particle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m_compute_dice_elbo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_trace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide_trace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_identically_zero\u001b[49m\u001b[43m(\u001b[49m\u001b[43melbo_particle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/pyro/lib/python3.12/site-packages/pyro/infer/traceenum_elbo.py:374\u001b[0m, in \u001b[0;36mTraceEnum_ELBO._get_traces\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraceEnum_ELBO does not support GuideMessenger\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_plate_nesting \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 374\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_guess_max_plate_nesting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mguide\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvectorize_particles:\n\u001b[1;32m    376\u001b[0m     guide \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_vectorized_num_particles(guide)\n",
      "File \u001b[0;32m~/miniconda3/envs/pyro/lib/python3.12/site-packages/pyro/infer/elbo.py:171\u001b[0m, in \u001b[0;36mELBO._guess_max_plate_nesting\u001b[0;34m(self, model, guide, args, kwargs)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_validation_enabled():\n\u001b[1;32m    170\u001b[0m     guide_trace\u001b[38;5;241m.\u001b[39mcompute_log_prob()\n\u001b[0;32m--> 171\u001b[0m     \u001b[43mmodel_trace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_log_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m site \u001b[38;5;129;01min\u001b[39;00m sites:\n\u001b[1;32m    173\u001b[0m         check_site_shape(site, max_plate_nesting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/pyro/lib/python3.12/site-packages/pyro/poutine/trace_struct.py:270\u001b[0m, in \u001b[0;36mTrace.compute_log_prob\u001b[0;34m(self, site_filter)\u001b[0m\n\u001b[1;32m    268\u001b[0m     _, exc_value, traceback \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n\u001b[1;32m    269\u001b[0m     shapes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat_shapes(last_site\u001b[38;5;241m=\u001b[39msite[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 270\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    271\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError while computing log_prob at site \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    272\u001b[0m             name, exc_value, shapes\n\u001b[1;32m    273\u001b[0m         )\n\u001b[1;32m    274\u001b[0m     )\u001b[38;5;241m.\u001b[39mwith_traceback(traceback) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    275\u001b[0m site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munscaled_log_prob\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m log_p\n\u001b[1;32m    276\u001b[0m log_p \u001b[38;5;241m=\u001b[39m scale_and_mask(log_p, site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscale\u001b[39m\u001b[38;5;124m\"\u001b[39m], site[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmask\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/pyro/lib/python3.12/site-packages/pyro/poutine/trace_struct.py:264\u001b[0m, in \u001b[0;36mTrace.compute_log_prob\u001b[0;34m(self, site_filter)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlog_prob\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m site:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 264\u001b[0m         log_p \u001b[38;5;241m=\u001b[39m \u001b[43msite\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m            \u001b[49m\u001b[43msite\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msite\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43margs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msite\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mkwargs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    268\u001b[0m         _, exc_value, traceback \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()\n",
      "File \u001b[0;32m~/miniconda3/envs/pyro/lib/python3.12/site-packages/torch/distributions/bernoulli.py:109\u001b[0m, in \u001b[0;36mBernoulli.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_prob\u001b[39m(\u001b[38;5;28mself\u001b[39m, value):\n\u001b[1;32m    108\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_args:\n\u001b[0;32m--> 109\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m     logits, value \u001b[38;5;241m=\u001b[39m broadcast_all(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogits, value)\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mbinary_cross_entropy_with_logits(logits, value, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/pyro/lib/python3.12/site-packages/torch/distributions/distribution.py:297\u001b[0m, in \u001b[0;36mDistribution._validate_sample\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mreversed\u001b[39m(actual_shape), \u001b[38;5;28mreversed\u001b[39m(expected_shape)):\n\u001b[1;32m    296\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m j \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m j:\n\u001b[0;32m--> 297\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    298\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValue is not broadcastable with batch_shape+event_shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mactual_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m vs \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    299\u001b[0m         )\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    301\u001b[0m     support \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupport\n",
      "\u001b[0;31mValueError\u001b[0m: Error while computing log_prob at site 'r':\nValue is not broadcastable with batch_shape+event_shape: torch.Size([2, 5]) vs torch.Size([1, 2]).\nTrace Shapes:      \n Param Sites:      \n        theta      \n        alpha      \nSample Sites:      \n     z_0 dist     |\n        value     |\n     log_prob     |\n     z_1 dist     |\n        value     |\n     log_prob     |\n       z dist   2 |\n        value   2 |\n     log_prob   2 |\n       r dist 1 2 |\n        value 2 5 |"
     ]
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "svi = SVI(model, guide, pyro.optim.Adam({\"lr\": 1}), loss=pyro.infer.TraceEnum_ELBO())\n",
    "num_steps = 1000\n",
    "for step in range(num_steps):\n",
    "    loss = svi.step(r)\n",
    "    if step % 100 == 0:\n",
    "        print(\"Step {}: loss = {:.2f}\".format(step, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "id": "2efacb10-6a8a-4f93-9379-e0ddf4fe1006",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_samples = {param: pyro.param(param).detach().clone() for param in pyro.get_param_store().keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "id": "04d26df4-d658-46a7-aa1f-427454c68771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'theta': tensor(1.0000), 'pi': tensor(0.0800), 'alpha': tensor(10.)}"
      ]
     },
     "execution_count": 977,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posterior_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 822,
   "id": "02b42685-bd42-4f82-973a-bbb4cc284c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0., -1.,  1.,  0.,  0.],\n",
      "        [ 0., -1.,  1.,  1.,  1.],\n",
      "        [ 1., -1.,  1.,  0.,  1.],\n",
      "        [ 0., -1.,  0.,  0.,  0.],\n",
      "        [ 1., -1.,  0.,  1.,  1.]])\n"
     ]
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "z, r, t, d =model(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 955,
   "id": "962eacf6-34ce-43df-a391-abb57ab50a51",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample [0]: 100%|█████████████████████████████████| 1100/1100 [00:00, 30432.20it/s, step size=1.00e+00, acc. prob=1.000]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "tensor([0.0833, 0.0833, 0.8333])\n",
      "tensor([0.0769, 0.0769, 0.0769, 0.7692])\n",
      "tensor([0.0714, 0.0714, 0.0714, 0.0714, 0.7143])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample [1]: 100%|█████████████████████████████████| 1100/1100 [00:00, 37270.66it/s, step size=1.00e+00, acc. prob=1.000]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "tensor([0.0833, 0.0833, 0.8333])\n",
      "tensor([0.0769, 0.0769, 0.0769, 0.7692])\n",
      "tensor([0.0714, 0.0714, 0.0714, 0.0714, 0.7143])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample [2]: 100%|█████████████████████████████████| 1100/1100 [00:00, 36940.31it/s, step size=1.00e+00, acc. prob=1.000]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "tensor([0.0833, 0.0833, 0.8333])\n",
      "tensor([0.1538, 0.0769, 0.7692])\n",
      "tensor([0.1429, 0.1429, 0.7143])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample [3]: 100%|█████████████████████████████████| 1100/1100 [00:00, 37601.75it/s, step size=1.00e+00, acc. prob=1.000]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "tensor([0.0833, 0.0833, 0.8333])\n",
      "tensor([0.0769, 0.0769, 0.0769, 0.7692])\n",
      "tensor([0.0714, 0.0714, 0.0714, 0.0714, 0.7143])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample [4]: 100%|█████████████████████████████████| 1100/1100 [00:00, 37284.21it/s, step size=1.00e+00, acc. prob=1.000]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "tensor([0.0833, 0.0833, 0.8333])\n",
      "tensor([0.0769, 0.0769, 0.0769, 0.7692])\n",
      "tensor([0.0714, 0.0714, 0.0714, 0.0714, 0.7143])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample [5]: 100%|█████████████████████████████████| 1100/1100 [00:00, 36703.16it/s, step size=1.00e+00, acc. prob=1.000]                                                                                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "tensor([0.0833, 0.0833, 0.8333])\n",
      "tensor([0.0769, 0.1538, 0.7692])\n",
      "tensor([0.1429, 0.1429, 0.7143])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup:   0%|                                                                                                                                                                               | 0/1100 [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "tensor([0.0833, 0.0833, 0.8333])\n",
      "tensor([0.0769, 0.0769, 0.0769, 0.7692])\n",
      "tensor([0.0714, 0.0714, 0.0714, 0.0714, 0.7143])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample [6]: 100%|█████████████████████████████████| 1100/1100 [00:00, 33428.50it/s, step size=1.00e+00, acc. prob=1.000]                                                                                           \n",
      "Warmup:   0%|                                                                                                                                                                               | 0/1100 [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "tensor([0.0833, 0.0833, 0.8333])\n",
      "tensor([0.0769, 0.0769, 0.0769, 0.7692])\n",
      "tensor([0.1429, 0.0714, 0.0714, 0.7143])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample [7]: 100%|█████████████████████████████████| 1100/1100 [00:00, 36868.29it/s, step size=1.00e+00, acc. prob=1.000]                                                                                           \n",
      "Warmup:   0%|                                                                                                                                                                               | 0/1100 [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "tensor([0.0833, 0.0833, 0.8333])\n",
      "tensor([0.0769, 0.0769, 0.0769, 0.7692])\n",
      "tensor([0.0714, 0.0714, 0.0714, 0.0714, 0.7143])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample [8]: 100%|█████████████████████████████████| 1100/1100 [00:00, 35496.54it/s, step size=1.00e+00, acc. prob=1.000]                                                                                           \n",
      "Warmup:   0%|                                                                                                                                                                               | 0/1100 [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "tensor([0.1667, 0.8333])\n",
      "tensor([0.1538, 0.0769, 0.7692])\n",
      "tensor([0.1429, 0.1429, 0.7143])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n",
      "tensor([1.])\n",
      "tensor([0.0909, 0.9091])\n",
      "Z_1\n",
      "Sample: tensor([[[[0]]],\n",
      "\n",
      "\n",
      "        [[[1]]]])\n",
      "Sample Shape: torch.Size([2, 1, 1, 1])\n",
      "Probs tensor([0.0909, 0.9091])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sample [9]: 100%|█████████████████████████████████| 1100/1100 [00:00, 37103.41it/s, step size=1.00e+00, acc. prob=1.000]                                                                                           \n"
     ]
    }
   ],
   "source": [
    "pyro.clear_param_store()\n",
    "nuts_kernel = NUTS(model=model)\n",
    "mcmc = MCMC(kernel=nuts_kernel, num_samples=1000, num_chains=10, warmup_steps=100)\n",
    "posterior = mcmc.run(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "9e2f6deb-1d8e-4bc7-8ec0-2096ee4ec403",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive = pyro.infer.Predictive(model, guide=guide, num_samples=10000)\n",
    "svi_samples = predictive(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "id": "53e6ed54-343c-4af9-9b31-a125d62a00f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 854,
   "id": "5b73a7f2-84a2-43f0-9b09-421e290365fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 0.],\n",
      "        [1., 1., 1., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "data = torch.ones(4, 4)\n",
    "print(data)\n",
    "# pad(left, right, top, bottom)\n",
    "new_data = F.pad(input=data, pad=(0, 1, 0, 0), mode='constant', value=0)\n",
    "print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "id": "900fa26d-d9ad-4565-a668-a858b0509266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 3, 3, 3, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 866,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z_pad = F.pad(input=z, pad=(0,10-len(z)), mode='constant', value=0)\n",
    "z_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "id": "aa1994fa-04b7-4e4a-99ed-901df7c57720",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_objs = d.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "id": "6b6880c6-3bbb-4942-8450-26593de5559d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 1., 1., 0.],\n",
      "        [1., 1., 0., 1., 1.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [1., 0., 1., 1., 1.]])\n",
      "tensor([[0., 0., 1., 1., 0.],\n",
      "        [1., 1., 0., 1., 1.],\n",
      "        [0., 0., 1., 1., 0.],\n",
      "        [1., 0., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "print(r)\n",
    "r_ = F.pad(input=r, pad=(0,0,0,num_objs-r.shape[0]), mode='constant', value=0)\n",
    "print(r_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "id": "d16932ce-b8d2-4b32-a8e2-c99e3b19c8d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1., 1.],\n",
       "        [1., 0., 1., 1., 1.],\n",
       "        [1., 0., 1., 1., 1.],\n",
       "        [1., 0., 1., 1., 1.],\n",
       "        [1., 0., 1., 1., 1.]])"
      ]
     },
     "execution_count": 876,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_[z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "cdf3976e-f35f-4216-85d9-ee03a3a1acf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pyro\n",
    "from torch.distributions import constraints\n",
    "from pyro.distributions import Bernoulli, Categorical, MultivariateNormal, Normal\n",
    "from pyro.distributions.util import broadcast_shape\n",
    "from pyro.infer import Trace_ELBO, TraceEnum_ELBO, config_enumerate\n",
    "import pyro.poutine as poutine\n",
    "from pyro.optim import Adam\n",
    "\n",
    "smoke_test = ('CI' in os.environ)\n",
    "assert pyro.__version__.startswith('1.9.0')\n",
    "\n",
    "# We'll ue this helper to check our models are correct.\n",
    "def test_model(model, guide, loss):\n",
    "    pyro.clear_param_store()\n",
    "    loss.loss(model, guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "35a4264e-98b1-4347-8c4f-023dee733676",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dist.Bernoulli(torch.tensor([0.3,0.7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b456bc0f-a27f-4310-866a-83d21be691da",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = d.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "940039b4-add6-4428-83bf-948e55142600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0.])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "3f47d68c-a4f4-4cc6-89f5-fc18dbe0580b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "281048cf-8b0e-4cde-9408-3002b5b43f15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.event_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "30f4f011-0645-4594-a003-af148c1e58b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.batch_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be790d0-3f2b-4599-a8f5-8a095af243a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
